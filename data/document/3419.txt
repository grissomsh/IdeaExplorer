Hybrid Cloud Service Level Intelligence: Policy-Driven Automation of Remedial Actions Through Orchestrator Telemetry and Analytics

I developed the idea during the past few years of my exposure to data center and cloud orchestration requirements analysis and solution design. The full expression of the ideas presented here require several pages of specifications and architecture for each orchestration environment, not included here.
Solving for (a) Commoditization: ViPR-accessible storage availability and elasticity can be more directly controlled from the cloud orchestration engine (VMware Cloud Suite, Openstack, or Microsoft Cloud OS), where this solution is needed to enhance the orchestrator with a telemetry servlet, an analytics engine, a policy interface and scripting to execute intelligent remediation of degraded performance

Solving for (b) Workloads: Orchestration plugins are designed to specifically address feature gaps in the way that storage controllers maintain defined access performance levels based on workload type (transaction/small block/OLTP, versus large-block streaming, content delivery or file transfer, as examples)

Solving for (c) Automation: The policy-driven engine uses the orchestrator as the management hub, measuring application system health through criteria such as server response times, CPU utilization, etc. Analysis of system health history provides predictive problem/resolution capabilities, which can be implemented against service level policies either through manual alerts/recommendations and human intervention, or through an intelligent (learning) self-managing automation engine, designed to maintain service levels in an enterprise-class hybrid cloud environment.

Solving for (d) Interoperability with Cloud Fabrics: Plugins for VMware (vCloud Automation Center, vCD, vCO etc), Microsoft System Center (PRO pack) Openstack, or any cloud or SDDC solution with sufficiently large footprint, will provide dashboard integration with the orchestration toolset, and servers for telemetry and analytics provide the external support.

EMC provides the orchestrator plugins, telemetry and analytics servlets and solution design. Implemented at the EHC on-prem in the enterprise and off-prem in the service provider.  

To solve this challenge, any storage-as-a-service offering, either as an on-premise EMC Hybrid Cloud Service Offering, or off-premise from EHC-powered or EHC-certified service providers or, more generally, any infrastructure-as-a-service offering, and by extension, any defined service level offering to enterprise, such as those offered by EMC Cloud Service Provider Partners to enterprise customers through EMC Hybrid Cloud orchestration and made available in the EMC Hybrid Cloud Services Catalog, should feature sophisticated cloud performance telemetry and resource capacity remediation, if prototypically under manual control, ultimately available as a policy-driven, intelligently automated degradation detection and remediation engine.

The proposed solution provides scaling automation to match varying load with resource capacity. This is accomplished through instrumented telemetry, data logging, analytics and resource provisioning/deprovisioning scripts, executed via plugins in the cloud orchestration tier. 

Use case examples:
1)	SAP ERP reporting during quarterly closing.  Well-managed 3-tier cloud applications use orchestrated provisioning and load balancing to manage a variable number of simultaneous http client connections and authentication sessions.  In addition, middle tier BI application modules should also be provision-able to respond to demand increases.  In this example, a web front end handles web clients for an SAP ERP solution.  During quarterly close, more clients access reporting through the web tier, and as a result there are more requests for the BI reports content depot modules in the application tier, and the data tier experiences greater read/write loading.  All three tiers are built using VM clusters that can be dynamically scaled then addressed algorithmically (round robin, weighted, least connections, etc.) through Layer 4-7 as well as geographic load balancing.  This solution for Use Case Example 1 detects degradation in https client response times, compares levels them to predefined policies, and provisions more servers as required, then de-provisions VMs as the client demand load subsides. The equivalent process plays out in the application tier (reporting modules added and removed) and the data storage tier (providing additional IOPS to meet transaction rate demand) 
2)	In the generalized content depot commodity storage use case, a file sync and share service (Syncplicity) makes use of a load-balanced dynamically allocated compute tier as the storage front end. This compute tier handles entropy encoding/decoding, in-flight and at-rest encryption/decryption, image thumbnailing, etc.) The scalability and elasticity of that compute tier will be the primary determinant for user experience (availability, sync versioning accuracy, etc.)  and  area of sensitivity.  While manual intervention may be acceptable for small deployments, automated provisioning/deprovisioning of resources in this tier will ultimately be required to meet service provider manageability and service level assurance requirements for millions of end users.


