Deduplication of Video Collateral
I am addressing the "New Business Challenge" that was provided by the Office of the CTO.  My idea is centered on long-term video archival.  You might think we already address this with Isilon and other devices, however, my idea adds deduplication to the s
This idea spawned a few years ago after meeting with a customer of mine called Notre Dame University.  I bet you have heard of them! They are in the middle of a multi year archiving project for all of the video data that is distributed across campus.  Their answer today is a Fuji Film system that archives data to tape.  Yup, tape is still heavily used in this industry and it is the preferred medium because "disk is too expensive."  I provided them one of our old "Tape Sucks" bumper stickers used by the old BURA team. They were not amused.

At this point my idea is purely a set of high level thoughts with a basic logical design and workflow.  I am the sole possessor of the idea and it has not been distributed. 
To address this problem we need to think outside of our normal storage mindset.  Instead, we need to think about the basics of rich media.  A video is a set of still frames that are animated together.  There might be 60-100 frames that pass in each second.  I am proposing that we gain additional insight from these still frames.  The root of any color is a pixel.  This pixel will have a specific numerical pattern associated to it.  This numerical pattern is a number that effectively describes the reds, blues, greens, etc.  Each pixel already has a basic fingerprint!  I propose we use some of our Avamar and Data Domain technology to start hashing, deduplicating, and compressing these fingerprints.  If you think about it the same color of blue will appear multiple times in a single frame.  Why not store that color one time for each frame?  Why not reference that deduplicated frame multiple times in the entire video? Do the same for red, green, and yellow and you have a much smaller version that what you started with. Now that we have smaller chunks of data why not send it to an object store using Cloud Boost?  Instead of a flat pre compressed file we instead have thousands  of text based descriptors that can be used to rebuild each frame into the entire video if needed.  Of course this will require some very efficient code and probably a hardware device with a good amount of IO capabilities (I call it the "blender") but luckily we have access to this type of machinery and the high level code with our products in CTD.
I believe that video needs something better than a "bigger mousetrap."  If EMC can be first to market with this type of technology we can be a huge disruptor in this field.  This would not only improve customer experience but it would also drive additiona
