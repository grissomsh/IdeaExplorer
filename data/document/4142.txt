Efficient auto-scaling of VMs using future load prediction

This idea was designed as a part of an academic project. It was implemented on a small cloud setup using EUCALYPTUS to verify the improvement in response time using the above method. The idea presented here can be adapted to any of the cloud platform that is supported by EMC to efficiently handle cloud application workload.
Presently, auto-scaling for cloud platforms like Amazon EC2 or Windows Azure are rule-based or threshold-based because of its simplicity. They do not take into consideration the future workload prediction while scaling up or scaling down of resources. In reality, various factors like “VM-turnaround time”, “VM-stabilization time”, etc. affect a newly started VM from start time to request service time. These factors can have a direct effect on the SLA violation.
The idea here is to have an insight of load in near future for a cloud application, so that VM-termination can be suspended which results in minimizing the number of VMs started. We propose to forecast short term loads using statistical methods like ARIMA and double exponential smoothing by which VM-termination can be postponed; thus minimizing the number of new VMs started by using existing VMs.
The proposed approach has 2 modules: Predictor and Decision Maker. The predictor module takes the server logs and VM startup time as input and predicts the future workload using ARIMA and double exponential smoothing. The decision maker module takes the load forecast values as input from the predictor and decides 2 things. First, if a VM is near to termination, decide if it should be suspended or terminated based on the predicted workload. Secondly, if the future workload is higher, it calculates the number of VMs that needs to be started (percentage of scaling) to maintain the desired load on the VMs and the response time. These modules can be implemented between the load balancer and the cloud controller in any cloud architecture.


